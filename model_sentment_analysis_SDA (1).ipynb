{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4078313-4ec1-4686-82d4-624b3584d5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cleaned_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "\n",
    "# Load your cleaned CSV file\n",
    "df = pd.read_csv(\"C:/Users/96659/Downloads/Fnail_Result_Cleaning (1).csv\")\n",
    "\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c4065c-c09e-4f32-a911-1c18ae856279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>وليه ما ترقع قلبي وتابعني ترد فيني روح السعو...</td>\n",
       "      <td>ايجابي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>من نيتك السعودية عندها افشل نظام تعليمي روح ...</td>\n",
       "      <td>ايجابي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>روح تعطي بعيد انا جزائري وتحيا السعودية وطز ف...</td>\n",
       "      <td>ايجابي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>😅 الاثري البعير جايب هذا الثقبة لي داير روحو ي...</td>\n",
       "      <td>ايجابي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>في الرياض ❄️ فعاليات عالمية وتجارب فريدة وأماك...</td>\n",
       "      <td>ايجابي</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text Sentiment\n",
       "0    وليه ما ترقع قلبي وتابعني ترد فيني روح السعو...    ايجابي\n",
       "1    من نيتك السعودية عندها افشل نظام تعليمي روح ...    ايجابي\n",
       "2   روح تعطي بعيد انا جزائري وتحيا السعودية وطز ف...    ايجابي\n",
       "3  😅 الاثري البعير جايب هذا الثقبة لي داير روحو ي...    ايجابي\n",
       "4  في الرياض ❄️ فعاليات عالمية وتجارب فريدة وأماك...    ايجابي"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Load AraBERT tokenizer and model\n",
    "model_name = \"aubmindlab/bert-base-arabertv02-twitter\"  # Arabic Twitter-specific model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Function to perform sentiment analysis on Arabic tweets\n",
    "def get_arabic_sentiment(tweet):\n",
    "    # Check if tweet is a valid string\n",
    "    if not isinstance(tweet, str):\n",
    "        return \"غير معروف\"  # Return a default value for non-string inputs\n",
    "    inputs = tokenizer(tweet, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    scores = outputs[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    labels = [\"سلبي\", \"ايجابي\"]\n",
    "    return labels[scores.argmax()]  # Returns the label with the highest score\n",
    "\n",
    "# Ensure all values in 'cleaned_text' are strings, fill NaN with empty strings\n",
    "df['cleaned_text'] = df['cleaned_text'].fillna('').astype(str)\n",
    "\n",
    "# Apply the sentiment analysis to the 'cleaned_text' column\n",
    "df['Sentiment'] = df['cleaned_text'].apply(get_arabic_sentiment)\n",
    "\n",
    "# Display the tweets with their respective sentiment\n",
    "df[['cleaned_text', 'Sentiment']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fdae0a8-c84d-42cb-86d1-1ca5fa823d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"D:/SDA_BootCamp/CAPSTONE/sentment/final_sentment_by_AHAHD_22.csv\", index=False,encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b38c14-cc4a-4e40-995e-4688da47760e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
